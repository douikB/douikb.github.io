---
title: "[25/06/20] - 생성형AI 활용을위한 머신러닝/딥러닝 (5일차)"
date: 2025-06-20 00:00:00 +0900
categories: ['SK 루키즈 교육','AI 머신러닝/딥러닝']
tags: ['교육']
---

<!--more-->




---


## ▫︎  분류(Classification)

- 주이전 데이터를 카테고리(범주)나 클래스로 분류하는 작업
- 데이터에 레이블(정답)이 존재
- 주요 목표
    - 정확한 예측
    - 실용적 적용

## ▫︎  특징

- 입력 데이터 - 다양한 특징을 가진 데이터
- 출력 데이터 - 데이터가 속한 범주 or 클래스
- 클래스 개수
    - 이진 분류 - 2개의 클래스만 예측
    - 다중 클래스 분류 - 3개 이상 클래스 예측

## ▫︎  작동 방식

1. 데이터 수집 및 전처리
2. 모델 학습
3. 모델 예측
4. 평가

## ▫︎  로지스틱 회귀(Logistic Regression)

- 분류 문제 해결하기 위한 지도 학습 알고리즘
- 데이터 클래스로 분류하는데 사용
- 데이터 분석하고 특정 데이터가 특정 클래스에 속할 확률을 예측
- 작동 원리
    - 선형 회귀 확장
    - 시그모이드 함수 적용
    - 클래스 결정
- 과정
    - 가설 설정
    - 손실 함수 정의
    - 모델 학습


- 분류 모델 성능 평가하기 위해 다양한 평가 지표 사용

## ▫︎  혼동 행렬(Confusion Matrix)

- 모든 평가 지표는 혼동 행렬 기반으로 계산
- 종류
    - **정확도 ⇒ 클래스가 균형 잡혀 있을때 적합**
        - 모델이 올바르게 예측한 비율
        - 전체적 예측 성능 간단히 측정가능
        - 단점 : 데이터 클래스 불균형에서 신뢰도가 낮아질 수 있음
    - **정밀도 ⇒ False Positive가 중요한 경우**
        - 모델이 Positive로 예측한 것들 중 실제로 Positive인 비율
        - False Positive 줄이는데 중점
        - 단점 : Positive 데이터 놓칠 수 있음(Recall 낮아질 수 있음)
    - **재현율 ⇒ False Negative가 중요한 경우**
        - 실제로 Positive 중에 모델이 Positive로 올바르게 예측한 비율
        - False Negative 줄이는데 중점
        - 단점 : Positive 로 예측하는 경향이 커져 정밀도가 낮아짐
    - **F1-Score ⇒ 정밀도와 재현율의 균형이 중요할 때**
        - 정밀도(Precision)와 재현율(Recall)의 조화 평균(Harmonic Mean)으로, 두 지표의 균형을 평가
        - 종합적인 성능 평가 가능
        - 단점 :  클래스 불균형이 심한 데이터에서는 추가적인 분석이 필요
- 구성 요소
    - True Positive(TP)
    - True Negative(TN)
    - False Positive(FP)
    - False Negative(FN)

## ▫︎  사이킷런을 이용한 분류 성능 평가 예제

```python
정확도(Accuracy): 0.956140350877193
정밀도(Precision): 0.9459459459459459
재현율(Recall): 0.9859154929577465
F1-Score: 0.9655172413793104

혼동 행렬 (Confusion Matrix):
 [[39  4]
 [ 1 70]]

분류 보고서 (Classification Report):
               precision    recall  f1-score   support

           0       0.97      0.91      0.94        43
           1       0.95      0.99      0.97        71

    accuracy                           0.96       114
   macro avg       0.96      0.95      0.95       114
weighted avg       0.96      0.96      0.96       114
```

- 지표 값 출력
    - 정확도 :  모델이 전체 데이터 중 95%를 정확히 예측.
    - 정밀도 : 양성으로 예측한 데이터 중 94%가 실제로 양성.
    - 재현율 : 실제 양성 데이터 중 98%를 정확히 양성으로 예측.
    - F1-Score : 정밀도와 재현율의 조화 평균(균형).
- 혼동 행렬 출력
    - 39:   실제 음성 데이터를 음성으로 예측 (TN).
    - 4  :   실제 음성 데이터를 양성으로 잘못 예측 (FP).
    - 1  :   실제 양성 데이터를 음성으로 잘못 예측 (FN).
    - 70:   실제 양성 데이터를 양성으로 예측 (TP).
- 분류 보고서 출력
    - 클래스 0(음성)
    정밀도 97%, 재현율 91%, F1-Score 94%.
    - 클래스 1(양성)
    정밀도 95%, 재현율 99%, F1-Score 97%.
    - 매크로 평균 :   각 클래스의 단순 평균.
    - 가중 평균 :   클래스 비율에 따라 가중치를 둔 평균.


## ▫︎  K-최근접 이웃(KNN) 알고리즘

- 가까운 데이터가 비슷한 특성을 가진다는 가정
- 사용하면 좋을 때
    - 데이터 패턴이 비선형적이고 복잡할때
    - 고차원인 경우 성능저하 가능성 → 차원 축소/데이터 전처리 필요
- 작동 원리
    - 훈련 데이터 준비
    - 거리 계산 → 흔하게는 유클리드 거리 사용
    - K개의 이웃 선택
    - 결과 결정
- 주요 특징
    - 모델 학습이 필요하지 않음
    - 단순성
    - 다양한 응용 - 분류/회귀 문제에 모두 사용할 수 있음

## ▫︎  K 값 선택과 영향

- K 값 → 매우 중요한 하이퍼 파라미터
    - 모델이 예측할 때 고려하는 가장 가까운 이웃 수
    - K값 선택은 모델의 성능에 큰 영향
    - 새로운데이터가 주어졌을 때, 이 데이터와 가장 가까운 K개의 데이터 포인터를 기반으로 예측 수행
- 장점
    - 모델이 데이터의 세부적 패턴 잘 잡아냄
    - 국소적 특징에 민감해 복잡한 데이터 처리에 적합
- 단점
    - 과적합 위험 증가
    - 노이즈에 영향을 크게 받음
- 고려사항
    - 데이터 크기
        - 작은 데이터 셋 → K값 작게 설정
        - 큰 데이터 셋 → K값 더 크게 설정
    - 홀수 값 선택
        - K는 보통 홀수로 설정하는게 좋음 → 동률 방지
    - 성능 평가를 위한 테스트교차 검증(Cross Validation)
        - 과적합/과소적합 사이 최적의 K 값 선택

## ▫︎  모델 성능 향상 및 하이퍼 파라미터 튜닝

- 모델 성능 향상 방법
    - 데이터 전처리
        - 스케일링, 이상치 제거, 특성 선택
    - 거리 계산 방식
        - 유클리드, 맨해튼, 민코프스키
    - 하이퍼파라미터 튜닝
        - 최적의 K 값 교차 검증으로 선택. 가중치 부여해 더 나은 성능 도출