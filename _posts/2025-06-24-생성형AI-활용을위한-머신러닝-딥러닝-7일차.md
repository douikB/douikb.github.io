---
title: "[25/06/24] - 생성형AI 활용을위한 머신러닝/딥러닝 (7일차)"
date: 2025-06-24 00:00:00 +0900
categories: ['SK 루키즈 교육','AI 머신러닝/딥러닝']
tags: ['교육']
---

<!--more-->




---


- 인공 신경망(Artificial Neural Network) 기반으로 한 머신러닝 하위분야
- 계층적 데이터 학습
    - 여러 층(레이어)로 구성된 신경망 사용
        - 층은 데이터에서 점점 더 높은 수준의 추상적 특징 학습 가능
- 주요 특징
    - 비정형 데이터 처리에 강함
    - 대규모 데이터와 연산 요구
    - 자동화된 학습
- 활용 분야
    - 컴퓨터 비전
    - 자연어 처리(NLP) : 챗봇
    - 음성 처리
    - 의료
    - 추천 시스템
    - 금융

## ▫︎  머신러닝 딥러닝 차이

- 머신러닝
    - 명시적 프로그래밍 없이 데이터 학습해 예측이나 분류할 수 있게 한 기술
    - 데이터에서 특징 추출하고 이 특징 바탕으로 패턴 학습해 결과 예측
    - 수작업으로 데이터 전처리하고 중요한 특징 선정해야 함
    - 제공된 특징 기반으로 학습
    - 상대적으로 적은 양의 데이터로도 학습 가능 → 관련 알고리즘이 많음
- 딥러닝
    - 머신러닝의 하위 분야
    - 인공 신경망을 기반으로 한 기술
    - 데이터 학습 과정에서 특징 자동 추출
    - 계층적인 학습(여러 레이어) 통해 복잡한 패턴 이해하고 학습
    - 자동 특징 학습
    - 매우 큰 데이터셋 필요 → 계층이 깊고 복잡해 충분히 많은 데이터를 사용해야 높은 성능 보장
    - GPU나 TPU 같은 강력한 연산 자원 필요


## ▫︎  인공지능 분류

- 약인공지능
    - 한 분야 집중해 인공지능 실현
    - 음성인식, 얼굴인식 등
- 강인공지능
    - 인간이 하는 행동 수준 또는 그 이상 행동
    - 터미네이터 스카이넷, 프로메테우스 데이빗 등

## ▫︎  인공신경망

- 뉴런의 구조
    - 신경 세포체
    - 가지돌기
        - 다른 뉴런으로부터 신호 받아들이는 역할(input)
    - 축삭돌기
- 퍼셉트론
    - 가장 기본적인 구성요소
    - 여러 입력 받아 하나의 출력을 생성
    - 구조
        - 입력
        - 가중치
            - 입력값이 얼마나 중요한지 나타내는 역할
        - 편향
            - 계산에 더해지는 추가값 → 더 유연하게 만듦
        - 합산기
        - **활성화 함수**
            - 합산된 값 S가 특정 임계값 넘는지 확인
            - S > 임계값 : 출력 1
            - S ≤ 임계값 : 출력 0
        - 출력
    - 동작 원리
        - 입력 신호 수집
        - 가중합 계산
        - 할성화 함수 적용
        - 총합이 임계값 넘으면 1, 그렇지 않으면 0 출력
    - 학습과정
        1. 초기화
        2. 예측 및 오차 계산
        3. 가중치 및 편향 업데이트
        4. 반복
    - 한계
        - 선형분리 문제는 잘 해결하지만 XOR 문제처럼 복잡한 문제 해결 못함
            - 극복 위해 다층 퍼셉트론(MLP)같은 더 복잡한 구조가 개발됨

## ▫︎  인공신경망 구조

- 입력층, 은닉층, 출력층의 계층적 구조
- 입력층
    - 입력 받는 층
    - 입력 데이터 각 특징은 하나의 뉴런에 대응
- 은닉층
    - 모든 뉴런과 연결되며, 완전 연결이라고 함
    - 은닉층 개수와 뉴런 수는 문제 복잡도에 따라 결정
    - 다층 구조 은닉층을 가진 신경망 = 심층 신경망(Deep Neural Network, DNN)
- 출력층
    - 문제 유형에따라 뉴런 수와 활성화 함수 달라짐
        - 회귀 문제
        - 이진 분류 문제
        - 다중 분류 문제

## ▫︎  신경망 동작 원리

- 신경망은 입력 데이터 받아 순전파와 역전파 과정을 통해 학습
- 순전파
    - 입력층에서 시작해 은닉층 거쳐 출력층까지 전달하며 계산 수행
- 손실함수
    - 출력층에서 예측값과 실제값 차이 계산하는 함수
        - MSE → 회귀 문제
        - Cross-Entropy Loss : 분류 문제
- 역전파
    - 손실 최소화 위해 가중치와 편향값 조정
    - 경사하강법 알고리즘 사용해 가중치 업데이트


## ▫︎  활성화 함수

- 입력 값 기반으로 출력값 비선형적으로 변환해 복잡합 패턴과 관계 학습
- 역할
    - 비선형성 추가
    - 출력 범위 제한
    - 특정 특징 강조
- 종류
    - ReLU (Rectified Linear Unit) - 대부분 은닉층에서 사용
    - Sigmoid - 이진분류 문제에서 자주 사용
    - Softmax - 다중클래스 분류 문제에서 사용

## ▫︎  손실함수

- 모델이 예측한 값과 실제값 간 차이를 측정 → 학습의 방향과 성능 평가 기준
- 기능
    - 성능평가
    - 학습방향 제공
        - Adam(효율적인 경사 하강법 알고리즘)
    - 문제 유형에 따라 손실함수 선택
        - 회귀와 분류 문제에 적합한 손실함수가 다름
- 종류
    - MSE (Mean Squared Error) - 회귀문제, 실수값출력, 큰 오류에 민감(제곱계산)
    - Cross-Entropy Loss - 분류문제, 확률 값(0~1사이), 잘못된 확률에 큰 패널티

## ▫︎  역전파(Backpropagation)

- 신경망 학습과정에서 오류 기반으로 가중치 조정하는 알고리즘
- 세부 단계
    - 순방향 전달
    - 손실 계산
    - 오류 역전파
    - 가중치 업데이트


- 복잡한 수학 연산이나 하드웨어 자원의 효율적 사용을 프레임워크가 처리해줌
- TensorFlow, Keras

## ▫︎  TensorFlow

- 복잡한 수학 연산 자동 처리
- 머신러닝, 강화학습, 딥러닝에 사용
- 특징
    - 유연성
    - 멀티 플랫폼 지원
    - 확장성

## ▫︎  Keras

- TensorFlow 기반 고수준 딥러닝 API
- 다양한 딥러닝 구조(CNN, RNN 등) 지원 하며, 필요에 따라 커스터마이징


- 주어진 데이터를 2개의 클래스로 구분하는 문제 해결 과정

## ▫︎  과정

1. 문제 정의
    1. 클래스 0 또는 클래스 1의 확률
2. 데이터 준비
    1. 데이터 수집
    2. 데이터 전처리
        1. 결측값 처리
        2. 특성 선택 및 정규화
        3. 데이터 분할
3. 모델 설계
    1. 입력층
    2. 은닉층
    3. 출력층 → 활성화 함수 : Sigmoid(출력값 0~ 1사이 확률로 변환)
4. 모델 컴파일
    1. 손실함수 :  Binary Cross-Entropy
    2. 최적화 함수 : Adam (또는 SGD)
    3. 평가지표 : 정확도(Accuracy), F1-Score, Precision, Recall 등
5. 모델 훈련
6. 과적합 방지
    1. Early Stopping →훈련중 검증 성능이 더이상 향상되지 않으면 조기에 학습 멈춤, 과적합 방지에 효과적
    2. Dropout → 학습 중 일부 노드 무작위로 제외해 과적합 방지
7. 모델 평가
8. 예측

## ▫︎  데이터셋

- 훈련, 검증, 테스트 데이터셋
1. 훈련 데이터셋
    1. 정의 모델 학습 시ㅣ키는데 사용되는 데이터셋
2. 검증 데이터셋
    1. 모델 성능 평가하기 위해 사용되는 데이터셋
    2. 과적합 감지하는데 사용
    3. 하이퍼 파라미터 튜닝시에도 사용
3. 테스트 데이터셋
    1. 학습 완료 후 모델의 최종 성능 평가하기 위해 사용되는 데이터셋
    2. 훈련이나 검증에서 본 적 없는 새로운 데이터로 구성
4. 데이터 분할 비율
    1. 데이터 적은 경우 교차 검층을 활용해 데이터 효율적 사용 가능
- 데이터 나누는 이유
    - 과적합 방지
    - 모델 성능 평가
    - 데이터 유출 방지


- 입력 데이터를 여러 클래스 중 하나로 분류하는 문제

## ▫︎  과정

1. 데이터 준비
    1. 수집
    2. 전처리
        1. One-Hot Encoding
        2. 정규화
    3. 데이터 분리
2. 모델 설계
    1. 입력층
    2. 은닉층
    3. 출력층 → Softmax 활성화 함수 사용
3. 모델 훈련
    1. 손실함수
    2. 옵티마이저
    3. 훈련 프로세스
4. 모델 평가
    1. 정확도
    2. 혼동 행렬
    3. 클래스별 평가
5. 모델 평가 → 학습된 모델 사용해 새로운 데이터 예측
    1. 예측은 Softmax 출력 기반으로 가장 높은 확률 값 가진 클래스 선택


## ▫︎  특징

- 가상머신에서 실행
- 최대 12시간 연속 사용 가능
- 암호화폐 채굴, 장기 백그라운드 실행 지원 X