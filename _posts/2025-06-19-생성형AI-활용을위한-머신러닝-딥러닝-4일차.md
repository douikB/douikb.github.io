---
title: "[25/06/19] - 생성형AI 활용을위한 머신러닝/딥러닝 (4일차)"
date: 2025-06-19 00:00:00 +0900
categories: ['SK 루키즈 교육']
tags: ['교육']
image: images/thumbnail.png
---

<!--more-->




---


- 두 변수 간의 선형 관계의 강도와 방향을 나타내는 값
- 범위는 -1 ~ 1
    - 1 : 양의 상관관계(하나 증가시 다른것도 증가)
    - -1 : 음의 상관관계(하나 증가시 다른것 감소)
    - 0 : 상관관계 없음 (관계X, 비선형적)


- 여러 변수 간의 상관계수를 표 형태로 보여줌


- 하나의 독립변수(X)와 하나의 종속변수(Y) 사이의 관계를 모델링해 X를 이요해 Y를 예측하는 방법
- 데이터가 선형관계 가지고 있을때 유용
- 1차 방정식
    
    $$
    Y = aX + b
    $$
    
    - a : 기울기 (독립 변수가 1 증가할 때 종속 변수가 얼마나 증가하는가)
    - b : 절편 (독립 변수가 0일때 종속 변수의 예상 값)

## ▫︎  주요 개념

- 잔차(Residuals)
    - 실제 값과 회귀선(예측 값) 간의 차이
- 최소제곱법(Least Squared Method)
    - 잔차의 제곱합이 최소가 되도록 회귀선 찾는 방법
    - 최소일때 가장 적합한 선형 방정식 얻을 수 있음
- $R^2$값(결정 계수)
    - 회귀 모델이 데이터를 얼마나 잘 설명하는지 나타냄
    - 값의 범위는 0~1, 1에 가까울수록 회귀 모델이 데이터를 잘 설명

## ▫︎  변수 간 관계 분석

- 변수 간의 상관성이나 영향력 이해하고 한 변수가 다른 변수에 어떻게 영향 미치는지 분석하는 과정
- 관계
    - 상관관계
        - 두 변수간 변화가 함께 나타나는 경우(연관성 있음)
    - 인과관계
        - 한 변수의 변화가 다른 변수에 직접적 영향 미치는 경우
- 관계 분석 도구
    - 상관 계수
    - 산점도
    - 회귀 분석


- 데이터 기반으로 스스로 학습해서 패턴 발견하고 규칙(함수) 만듦

## ▫︎  지도학습

- 데이터와 함께 해당 데이터에 대한 정답(라벨) 제공해 모델이 학습하도록 하는 머신러닝 방법
    - 질문/답을 주고 학습
- 예측/분류 분야에 적용
- 사례
    - 스팸 메일 분류
    - 집값 예측
    - 이미지 분류
- **주요 알고리즘**
    - 회귀(Regression), 분류(Classification)

## ▫︎  비지도 학습

- 데이터에는 있지만 정답(라벨)은 주어지지 않은 상태에서 학습하는 머신러닝 방법
- 모델이 데이터 스스로 분석해 패턴이나 그룹 찾아냄(데이터 이해, 탐색)
- 사례
    - 고객 그룹화
    - 추천 시스템
    - 데이터 압축

## ▫︎  머신러닝

- 입력(Features)
    - 모델이 학습할 때 사용하는 데이터 특성
    - 데이터 구성하는 각각의 요소, 예측이나 분류에 영향을 미치는 중요한 정보
- 출력(Target)
    - 모델이 예측해야 하는 결과값. 목표값

## ▫︎  회귀 알고리즘(Regression)

- 연속적인 숫자(값) 예측하는 알고리즘
- 입력 데이터(Features)와 출력 값(Target)간의 수학적 관계(선형/비선형 관계)를 모델링
- 대표 알고리즘
    - 선형 회귀
        - $y = mx + b$ (직선 방정식)
            - x : 독립 변수
            - y : 종속 변수
            - m : 기울기
            - b : y절편
        - 손실 함수 : 평균 제곱 오차(Mean Squared Error; MSE)
            - 데이터 점과 직선 사이의 거리(오차)의 제곱 평균 계산
    - 다중 회귀
- 종류
    - 단순 선형 회귀
    - 다중 선형 회귀
    - 비선형 회귀
- 동작 방식
    - 학습 데이터 수집
        - 입력데이터(독립변수)와 정답(종속변수) 준비
    - 모델 학습
        - 입/출력 사이의 수학적 관계 찾음
    - 예측

## ▫︎  분류 알고리즘(Classification)

- 데이터를 미리 정해진 범주(Category) 중 하나로 분류하는 알고리즘
    - 예측 결과는 숫자가 아닌 범주(Label)
- 입력 데이터(Features)를 보고, 각 데이터가 어떤 범주에 속하는지 판단
- 대표 알고리즘
    - 로지스틱 회귀
    - 서포트 벡터 머신(SVM)
    - KNN


- 학습의 기반 → **훈련 Data**
    - 모델이 학습 하는데 필요한 정보제공
    - 입/출력 관계 파악
- 패턴 발견 및 예측 가능
- 모델 평가

## ▫︎  학습 데이터와 테스트 데이터 분리

- 왜?
    - 모델 과적합(Overfitting) 방지
        - 학습 데이터에 너무 특화되면, 새로운 데이터에 좋은 성능 내지 못할 수 있음
    - 모델의 일반화 능력 강화
        - 학습하지 않은 데이터에 대한 평가 가능

## ▫︎  데이터 분리 과정

- 특성과 타겟 분리
    - 특성(Features)
        - 예측에 사용할 데이터
    - 타겟(Target)
        - 예측하고자 하는 값
- 학습 데이터/테스트 데이터 분리
    - 학습용(80%), 테스트용(20%) 분리
    - `train_test_split` 함수 사용


## ▫︎  주요 성능 평가 지표

- 평균 제곱 오차(Mean Squared Error; MSE)
    - 오차(예측 값과 실제 값 차이)의 제곱 평균
    - MSE 값이 작을수록 모델이 더 정확함
    - **큰 오차에 민감한 평가 방법**(작은 실수 크게 보려는 돋보기 같은 역할)
    
    $$
    MSE=\frac{1}{n}\sum_{i=1}^n(y_i-\hat{y_i})^2
    $$
    
    - $y_i$ : 실제 값
    - $\hat{y_i}$ : 예측 값
    - $n$ : 데이터 개수
- RMSE(Root Mean Squared Error)
    - 평균 제곱근 오차MSE의 제곱근 계산한 값
    - **MSE 단위를 실제 값과 맞추어 해석하기 쉽게 만든 것**
    - 예측값과 실제 값의 평균적인 오차는 약 0.63

$$
RMSE = \sqrt{MSE}
$$

- MAE(Mean Absolute Error): 평균절대 오차
    - **오차의 절대값 평균 계산**
    - 큰 오차의 영향이 덜함
    - 평균적으로 모델은 실제값과 0.4점 정도 차이

$$
MAE=\frac{1}{n}\sum_{i=1}^n|y_i-\hat{y_i}|
$$

- R^2(R-squared) : 결정 계수
    - **모델이 데이터 얼마나 잘 설명하는지 나타냄**
    - 0~1사이의 값, 1에 가까울 수록 모델이 데이터 잘 설명함
    - 모델은 데이터를 약 99% 설명

$$
R^2 = 1  - \frac{SS_{res}}{SS_{hot}}
$$

- $SS_{res}$ : 잔차 제곱합(예측 값과 실제 값 차이)
- $SS_{hot}$ : 총 제곱합(실제 값과 평균 값 차이)


1. 데이터 준비
2. 모델 학습
3. 성능 평가
    - mean_squared_error: 평균 제곱 오차(MSE)를 계산
    - mean_absolute_error: 평균 절대 오차(MAE)를 계산
    - r2_score: 결정 계수(𝑅2R 2 )를 계산
4. 결과 시각화
5. 예측


- 성능과 관련된 문제
- 모델이 데이터에 너무 치우치거나 일반화 잘 하지 못할 때 발생

## ▫︎  과적합(Overfitting)

- 데이터 너무 많이 학습한 상태
    - 학습 데이터에서는 성능이 좋은데 새로운 데이터에서는 나쁨
    - 일반화 능력 부족
- 모델이 너무 복잡함
- 해결 방법
    - 모델의 복잡도 낮춤(간단한 모델 사용, 차원 축소)
    - 규제(Regularization) 적용
        - L1 규제 : 불필요한 특징 제거
        - L2 규제 : 가중치를 너무 크게 만드는 것 방지
    - 더 많은 데이터 수집하거나 교차 검증 사용

## ▫︎  과소적합(Underfitting)

- 데이터를 제대로 학습하지 못한 상태
    - 학습 데이터, 테스트 데이터 모두에서 성능 나쁨
- 모델이 너무 단순함
- 해결 방법
    - 모델을 더 복잡하게 만듦(더 많은 특징 추가, 더 큰 모델 사용)
    - 학습 데이터 더 많이 수집, 학습 시간 늘려 모델을 충분히 학습


**신용카드 사기 거래 탐지**

신용카드 사기 거래 탐지는 이진 분류 문제로, 주어진 거래가 정상인지 사기인지 예측

LogisticRegression 알고리즘 이용

Credit Card Fraud Detection  데이터 셋 사용

[https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)

구현 가이드

- **데이터 로드**: 신용카드 거래 데이터셋을 로드
- **특성과 레이블 분리**: 'Class' 열은 거래의 레이블(정상: 0, 사기: 1)을 나타내며, 이를 제외한 나머지 열은 특성으로 사용
- **데이터 분할**: 데이터를 학습 세트와 테스트 세트로 분할하여 모델의 성능을 평가
- **데이터 스케일링**: 특성 값의 범위를 표준화
- **모델 학습**: 랜덤 포레스트 분류기를 사용하여 학습 세트에 대해 모델을 학습
- **예측 및 평가**: 테스트 세트에 대한 예측을 수행하고, 정확도와 기타 평가 지표를 출력