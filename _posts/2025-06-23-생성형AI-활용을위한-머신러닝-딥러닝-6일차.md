---
title: "[25/06/23] - 생성형AI 활용을위한 머신러닝/딥러닝 (6일차)"
date: 2025-06-23 00:00:00 +0900
categories: ['SK 루키즈 교육']
tags: ['교육']
---

<!--more-->




---


- 정답(레이블)이 없는 데이터 기반으로 학습하는 머신러닝 방법
- 입력 데이터에 포함된 숨겨진 패턴이나 데이터 구조 파악하는데 초점 맞춤
    - 즉 모델이 데이터를 보고 스스로 규칙을 발견하거나 데이터를 특정 기준에 따라 그룹으로 나누는 것

## ▫︎  활용 분야

- 군집화(Clustering) - 데이터 비슷한 특성 가진 그룹으로 묶음
    - K-Means, DBSCAN
- 차원 축소(Dimensionality Reduction) - 데이터 간결하고 유용한 형태로 변환
    - 데이터 시각화, 노이즈 제거, 데이터 압축
    - PCA, t-SNE
- **이상치 탐지(Anomaly Detection)**
    - Isolation Forest, LOF, Autoencoder
- 추천 시스템(Recommendation System)

## ▫︎  지도 학습/비지도 학습 차이

| 구분 | 지도 학습 | 비지도 학습 |
| --- | --- | --- |
| 레이블 유무 | 정답(레이블) 제공 | 레이블 없이 입력 데이터만 제공됨 |
| 데이터 구조 이해 | 데이터-정답 관계 학습 | 데이터 간의 패턴과 관계 스스로 파악 |
| 결과물 | 새로운 데이터의 정답 예측 | 데이터의 그룹, 축소된 데이터 표현 |
| 적용 사례 | 예측 모델
(스팸 이메일 분류, 가격 예측) | 데이터 탐색
(고객 세분화, 시각화) |


- 주어진 데이터에서 유사한 특성 가진 데이터 포인트들 그룹으로 묶는것
    - 각 그룹 : 클러스터
    - 데이터 사전에 분류하지 않고 데이터 살펴보며 그룹 형성
- **주요 목표**
    - 데이터 구조 파악 - 시각화/그룹화 하여 숨겨진 패턴 발견
    - 유사성 기반 그룹화
- **작동 방식**
    - 유사성 측정 - 거리계산(ex. 유클리드 거리) 사용
    - 그룹화

## ▫︎  활용

- 고객 세분화
- 이미지 세그멘테이션
- 문서 분류 및 정보 검색
- 이상치 탐지
- 추천 시스템


- 데이터 군집화에서 가장 널리 사용되는 알고리즘 중 하나
- 주어진 데이터를 K개의 클러스터로 나누는 비지도 학습 방법

## ▫︎  알고리즘 원리

1. 초기 클러스터 중심(Centroid) 설정
    - 클러스터 개수(K)를 사용자가 미리 설정
    - 초기 클러스터 중심은 무작위로 설정하거나 데이터 기반으로 선택
2. 데이터 포인트 할당
    - 각 데이터 포인트를 가장 가까운 클러스터 중심에 할당
    - 유클리드 거리 사용해 계산
3. 클러스터 중심 재계산
    - 평균 위치 계산해서 새로운 클러스터 중심으로 설정
4. 반복
    - 클러스터 중심 할당하고 재계산
    - 클러스터 중심이 더이상 변하지 않거나(수렴) 최대 반복 횟수에 도달하면 알고리즘 종료

## ▫︎  적용

1. 데이터 준비
2. K 값 선택
    - 엘보우 방법 사용
3. 알고리즘 실행
4. 결과 평가 및 시각화

## ▫︎  클러스터링 결과 해석

- 시각적 분석
    - Matplotlib : 산점도(Scatter plot)
    - Seaborn : 페어 플롯(pair plot)
    - PCA : 고차원 데이터 → 2차원으로 축소
- 클러스터 중심 확인
    - 각 클러스터 중심(centroid) 확인
- 클러스터 내 데이터 평균, 분포 확인
    - 클러스터 별 속성 평균값과 분포 분석
    - 각 클러스터의 특성 확인
- 클러스터 간 차이점 파악
    - 클러스터를 서로 비교해 공통점, 차이점 확인

## ▫︎  적절성 평가

- 데이터 응집도
    - 클러스터 내의 데이터가 얼마나 가까이 모여 있는지를 분석
- 데이터 분리도
    - 다른 클러스터와 얼마나 잘 분리되어 있는지를 분석

## ▫︎  품질 평가

- 클러스터링 결과 잘 나왔는지 평가 과정
    - K-Means → 클러스터 내 데이터 응집도와 클러스터 간 분리도 확인
    - 적절한 클러스터 수 K를 선택하는게 중요 → 실루엣 점수로 확인
- **실루엣 점수**
    - 클러스터 응집도/분리도 동시 평가하는 강력한 지표
    - K-Means 품질 판단에 유용
    - **계산 공식**
        
        $$
        s(i) = \frac{b(i) - a(i)}{max(a(i),b(i))}
        $$
        
        - a(i) : 데이터 포인트 𝑖와 같은 클러스터 내 다른 포인트 간의 평균 거리 (응집도)
        - b(i) :  데이터 포인트 𝑖와 가장 가까운 다른 클러스터 포인트들 간의 평균 거리 (분리도)
        - s(i) 값 범위 $-1 \le s(i) \le 1$
    - 의미
        - s(i)가 1에 수렴 : 데이터 포인트가 클러스터에 잘 속해있고 다른 클러스터와 명확히 분리 됨
        - s(i)가 0에 수렴 : 데이터 포인트가 경계에 가까워져, 어느 클러스터에 속했어야 하는지 불확실
        - s(i)가 음수 : 데이터 포인트가 잘못된 클러스터에 속했을 가능성 높음
        - 데이터 셋 전체의 실루엣 점수는 모든 데이터 포인트 s(i) 값 평균으로 계산됨
            
            $$
            S = \frac{1}{n}\sum_{i=1}^n s(i)
            $$
            
    - 방법
        1. 여러 k 값에 대해 K-Means 실행
        2. 각 k값에 대해 실루엣 점수 계산
        3. 실루엣 점수 시각화
        4. 실루엣 점수가 가장 높은 k값을 선택

## ▫︎  K-Means 외 군집화 알고리즘

- Hierarchial Clustrering(계층적 군집화)
    - 데이터 포인트간 계층적 관계 기반 클러스터 혈성
        - 데이터가 트리 형태
        - 덴드로그램이라는 시각화로 표혐
    - 방법
        - 병합형
            - 개별 → 가까운 클러스터로 병합
        - 분할형
            - 모든 데이터를 하나의 클러스터로 시작해 점차 분리
    - 장점
        - 클러스터 수 미리 지정 필요 X
        - 덴드로그램으로 시각적 확인 가능
    - 단점
        - 큰 데이터셋에서는 계산 비용 높음
        - 클러스터 병합/분할이 초기 단계에 잘못되면 이후 결과에 영향 줌
    - 작동 방식
        1. 각 데이터 포인트를 하나의 클러스터로 간주
        2. 두 클러스터 간 거리(또는 유사도) 계산
        3. 가장 가까운 두 클러스터 병합
        4. 클러스터 하나 될 때까지 반복
    - 거리 계산 방법
        - 최단 연결법
        - 최장 연결법
        - 평균 연결법
- DBSCAN (Density-Based Spatial Clustering of Applications with Noise)
    - 밀도기반 클러스터링
        - 밀도 낮은 데이터 → 노이즈(이상치)
        - 클러스터 수 미리 지정할 필요 X
        - 밀도 다른 데이터나 비구형 데이터 효과적으로 처리, 이상치 검줄에 강점
        - 고차원 데이터에서는 거리계산 왜곡될 수 있음
    - 주요 매개변수
        - Epsilon ($\epsilon$) : 포인트가 밀집되었다고 판단할 거리의 임계값
        - MinPts : 한 포인트가 핵심 포인트가 되기 위한 최소 이웃 데이터 포인트 수
    - 동작 방식
        1. 각 데이터 포인트에 대해 $\epsilon$-이웃 계산
        2. $\epsilon$-이웃 내 데이터 포인트 수가 MinPts 이상이면 해당 포인트는 핵심(Core) 포인트로 간주
        3. 핵심 포인트와 연결된 이웃 데이터는 같은 클러스터로 그룹화
        4. 밀도 낮은 포인트는 노이즈로 분류


<aside>
💡

데이터가 고차원일수록(피처 개수가 많을 수록) 모델을 학습시키거나 분석할 때 여러가지 문제가 발생 가능

⇒ 이 문제 해결하기 위해 **차원 축소**가 필요

</aside>

## ▫︎  필요성

1. 고차원의 문제(Curse of Dimensionality)
    - 데이터 희소해짐
    - 학습 속도 저하
    - 과적합(Overfitting)
2. 데이터 시각화
3. 노이즈 제거
4. 모델 효율성 향상

### ▫︎  필요 사례

- 이미지 데이터
- 유전자 데이터
- 추천 시스템


- 고차원 데이터를 저차원으로 축소하면서도 데이터의 중요 정보를 최대한 보존하는 차원 축소 기법
    
    ⇒ 데이터 주요 특징 파악하고 노이즈 제거하거나 시각화 용이하게 함
    
- 데이터를 선형변화해 새로운 축(Principal Components, 주성분) 생성 과정
    - 주성분 : 데이터 분산을 가장 잘 설명하는 새로운 축
    - 데이터의 주요 패턴 찾기 : 분산이 가장 큰 방향 기준으로 데이터 분석
    - 축 변경
    - 차원 축소

## ▫︎  작동 원리

- 데이터를 새로운 좌표축으로 변환해 주요 특징 유지하면서 차원 줄임
1. 데이터 처음에 여러 차원(피처)으로 구성
2. 각 차원의 분산(정보량) 측정하고 분산이 가장 큰 방향(축) 찾음
3. 분산 가장 큰 방향으로 데이터 정렬해 새로운 축 정의
4. 새로운 축 기준으로 데이터를 변환(투영)하여 적은 차원에서도 데이터 잘 설명할 수 있게 처리

## ▫︎  적용 단계

1. 데이터 정규화
2. 주성분 축 찾기위한 공분산 행렬 계산
3. 주성분 축 찾기 위한 고유값(Eigenvalues)과 고유벡터(Eigenvectors) 계산
4. **주성분** 선택
5. 데이터 투영


- 데이터 분산(정보량)이 가장 큰 방향 나타내는 축
- 특징
    - 첫 번째 주성분(PC1)
        - 데이터의 분산이 가장 큰 방향. 데이터의 변동성을 가장 잘 설명하는 축
    - 두 번째 주성분(PC2)
        - 첫 번째 주성분에 수직(직교)한 축.  두 번째로 큰 분산을 설명하는 방향
    - 추가 주성분
    - 주성분의 수

## ▫︎  데이터 투영(Projection)의 의미

- 데이터를 기존 좌표축 대신 주성분 축으로 변환하는 과정
- 투영 후 데이터는 새로운 축(주성분) 상에서 표현
- 불필요한 차원(변동성 적은 축)은 제거
- 필요 이유
    - 중요한 정보만 유지
    - 차원 축소
    - 시각화


- 패턴과 크게 벗어나는 관측값 식별
- 목적
    - 데이터 품질 개선
    - 문제 예방

## ▫︎  비지도학습 기반 이상치 탐지

### ▫︎  Isolation Forest

- 이상치 탐지를 위해 설계된 비지도학습 알고리즘
- 데이터를 반복적으로 나누는 방식으로 이상치를 탐지
- 공간을 무작위로 분할
- 나눌수록 나머지 데이터에서 이상치가 더 빠르게 분리됨
- 작동 원리
    - 무작위 샘플링
    - 분리 깊이 계산
    - 여러 트리 구축
    - 이상치 점수 산출
- 장점
    - 효율성
    - 확장성
    - 비지도 학습
- 단점
    - 고차원 데이터에서 효율이 떨어질 수 있음
    - 분포가 매우 복잡한 데이터에는 성능이 제한될 수 있음
- 주요 응용 분야
    - 금융 사기 탐지
    - 네트워크 보안

### ▫︎  DBSCAN (Density-Based Spatial Clustering of Applications with Noise)

- 밀도 기반 클러스터링 알고리즘
- 데이터를 밀도가 높은 영역(군집)과 밀도가 낮은 영역(이상치)으로 나눔
- 주요 개념
    - Epsilon : 두 데이터 포인트가 같은 클러스터에 속하기 위해 허용되는 최대 거리
    - MinPts : 클러스터 형성위해 필요한 최소 데이터 포인트 수
    - Core Points
    - Border Points
    - Noise(이상치)
- 작동 원리
    - 각 데이터 포인트에서 $\epsilon$ 반경 내 데이터 밀도 계산
    - 밀도 높은 데이터 포인트(Core Point) 중심으로 클러스터 형성
    - 밀도 낮은 포인트는 Noise로 간주
- 장점
    - 클러스터 모양에 제약 없음(비구조적 데이터에서도 사용 가능)
    - 사전 클러스터 개수 지정 불필요
    - 이상치 탐지와 클러스터링 동시 수행
- 단점
    - $\epsilon$와 MinPts 파라미터 선택이 성능에 크게 영향 미침
    - 고차원 데이터에 적용시 효율성 저하