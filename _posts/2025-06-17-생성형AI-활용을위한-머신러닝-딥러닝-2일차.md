---
title: "[25/06/17] - 생성형AI 활용을위한 머신러닝/딥러닝 (2일차)"
date: 2025-06-17 00:00:00 +0900
categories: ['SK 루키즈 교육']
tags: ['교육']
image: images/thumbnail.png
---

<!--more-->

---

# ▪︎ 데이터 전처리

## ▫︎  데이터 전처리

- 데이터 분석, 머신러닝 모델에 사용 전 깨끗하고 유용한 상태로 준비하는 과정
- 데이터 수집 후 **누락된값, 오류, 중복** 수정 정리 과정
- 필요한 이유
    - 좋은 결과를 산출하기 위해서

## ▫︎  전처리의 중요성

- 데이터 품질을 높임
- 분석이나 모델링의 결과 신뢰성을 높임
- 시간과 비용 절약
- 의사결정의 정확성 향상
- 성공적인 데이터 프로젝트의 필수적인 단계

# ▪︎ 데이터 유형

## ▫︎  정형 데이터(Structured Data)

- 행/열로 구성되어 있는 잘 정리된 데이터
    - DB, 엑셀파일
- 은행 고객정보 데이터, 매출 데이터 등..

## ▫︎  비정형 데이터(Unstructured Data)

- 고정된 구조가 없는 정리되지 않은 데이터
    - 이미지, 동영상, 텍스트 파일

## ▫︎  반정형 데이터(Semi-Structured Data)

- 비정형-정형의 중간 단계로 정형 데이터처럼 엄격하진 않음
    - JSON, XML 파일
- 데이터 구조는 있지만 형태가 유연하며, 사람이 읽을 수 있고 컴퓨터도 처리 가능함

## ▫︎  전처리 과정

```python
수집 → 정제 → 변환 → 통합
```

- 정제 : 데이터를 깨끗하게 만드는 단계
    - 결측 값 처리 - 비어있는 값 처리
    - 오류 수정 - 잘못된 데이터(오타, 잘못된 값) 수정
    - 중복 제거 - 중복 데이터 삭제
    - 이상치 제거 - 정상적이지 않은 값 처리
- 변환 : 데이터 분석/모델링에 적합하게 바꾸는 단계
    - 형태 변환 - 데이터 사용 목적에 맞게 바꾸기
    - 정규화(Normalization) - 데이터 범위 일정하게 조정
    - 집계(Aggregation) - 데이터 요약하거나 그룹화
    - 차원 축소 - 불필요한 데이터 제거해 데이터 크기 줄임
- 통합
    - 데이터 병합(merging)
    - 일관성 유지
    - 중복 제거

# ▪︎ 데이터 정제(Cleaning)

- 결측치 처리(제거, 대체)
- 이상치 처리(IQR, Z-Score)
- 데이터 중복 확인 및 제거

## ▫︎  결측치

- 데이터셋에서 특정 값이 누락된 상태
- 데이터 분석 결과에 영향을 줄 수 있으므로 반드시 처리해야 함
- 처리 이유
    - 분석 왜곡 방지
    - 모델 학습 방해 방지
    - 데이터 품질 향상

## ▫︎  결측치 처리

- 제거
    - 사용상황 → 데이터셋에서 차지하는 비율이 매우 적어 분석에 큰 영향 주지 않을때
    - 열/행 제거
        - 사용상황 → 데이터 양이 적거나 결측치가 무작정 삭제되면 데이터 손실이 너무 클 때
        - 고정값으로 대체
            - 특정 값(0, 평균, 중간값)으로 결측치 채움
        - 통계 기반 대체
            - 평균값 대체 - 수치형 데이터에서 결측값 해당 열 평균으로 대체
            - 중간값 대체 - 평균이 극단값에 영향 받는 경우 사용
            - 최빈값 대체 - 범주형 데이터에서 가장 많이 등장한 값으로 결측치 대체
        - 예측 기반 대체
            - 머신러닝 모델 사용해 결측치 예측하여 채움
- 간단한 데이터셋 → 제거나 평균/중간값 대체가 유용
- 복잡한 데이터셋 → 머신러닝 기반 대체 활용

## ▫︎  이상치 처리

- **IQR(Interquartile Range) 방법**
    - IQR - 데이터 중간 50% 포함하는 범위 이용해 이상치 탐지하는 방법
        - 비대칭 분포 데이터에 적합
        - 극단값 영향 덜받음
    - Q1(1사분위수) : 하위 25%
    - Q3(3사분위수) : 상위 75%
    - IQR :  $IQR=Q3-Q1$
    - **이상치 기준**
        - 아래쪽 : $Q1-1.5\times IQR$
        - 위쪽 : $Q3+1.5\times IQR$
- **Z-Score 방법**
    - $Z=(X-\mu)/\sigma$
        - $X$ : 개별 데이터 값
        - $\mu$ : 평균
        - $\sigma$ : 표준 편차
    - **이상치 기준**
        - 일반적으로 $|Z|>3$ 이면 이상치로 간주

# ▪︎ 중복 데이터

- 데이터셋에서 동일한 행(row)이 반복적으로 나타나는 것
- 결과 왜곡, 처리속도,  메모리 사용량에 영향 줌
- 완전중복/부분중복이 있음

# ▪︎ 데이터 변환

- 데이터 분포 변화시켜 분석이나 모델링에 유리한 형태로 만드는 과정
- 로그변환, 스퀘어 루트 변환은 데이터 처리시 자주 사용되는 기법
- 데이터 왜도(Skewness)를 줄이고 더 정규분포에 가깝게 만들기 위해 사용

## ▫︎  로그 변환

- 데이터 값 로그를 취하는 방법
- 값이 매우 크거나 몇 개가 지나치게 크고 나머지는 작은 경우 (오른쪽으로 치우친 분포)
- 변환시
    - 큰 값 축소
    - 작은 값 상대적으로 더 커짐
    - 데이터 분표 평탄하게
- 주의점
    - 데이터에 0이나 음수 있으면 로그 계산할 수 없어 변환 전 값에 작은 상수를 더해야함
        
        ex) log(x+1)
        

## ▫︎  스퀘어 루트 변환

- 제곱근 구하는 방법
- 로그 변환보다 덜 극단적임
- 데이터 크기 축소하거나 오른쪽 치우침을 완화
- 주의점
    - 음수 값에 사용할 수 없음(음수에는 제곱근이 실수로 정의되지 않음)

## ▫︎  비교

| 특성 | 로그 변환 | 스퀘어 루트 변환 |
| --- | --- | --- |
| 적용 대상 | 매우 큰 값, 오른쪽 치우친 분포 | 작은 값과 큰 값이 공존하는 분포 |
| 효과 | 큰 값을 더 크게 줄임 | 큰 값을 약간 줄임 |
| 수식 | y=log(x) | y=x |
| 제약 조건 | 음수/0에 사용 불가 | 음수에 사용불가 |

# ▪︎ 데이터 스케일링

- 데이터 값 범위 조정
- 머신러닝 모델이 데이터의 크기 차이에 영향을 덜 받게 하기 위해 중요
- 변수 단위나 크기 다를때 모델 학습시 필수적인 과정

## ▫︎  표준화(Standardization)

- 데이터 값을 평균이 0, 표준 편차가 1이 되도록 변환하는 방법
    - 공정한 비교
    - 표준편차 : 데이터가 평균에서 얼마나 떨어져 있는지 측정한 값
- 분포 모양을 바꾸지 않고 단위 차이를 없애주는 것
- **수식**
    
    $$
    z = \frac{x - \mu}\sigma
    $$
    
    - x : 원래 데이터 값
    - $\mu$ : 평균값
    - $\sigma$ : 표준 편차
- **장점**
    - 동일한 기준으로 변환
    - 거리기반 알고리즘(KNN, SVM)에서 효과적
- **주의점**
    - 데이터가 정규 분포 따르지 않더라도 표준화 적용 할 수 있지만 분포의 왜도가 남을 수 있음

## ▫︎  정규화(Normalization)

- 데이터를 0과 1사이로 변환
- 값의 크기를 줄이고 데이터를 일정한 스케일로 맞춤
- **수식(Min-Max Scaling)**
    
    $$
    x' = \frac{x - min(x)}{max(x) - min(x)}
    $$
    
    - x : 원래 데이터 값
    - min(x) : 데이터 최소값
    - max(x) : 데이터 최대값
- **장점**
    - 스케일에 민감한 알고리즘(신경망, 회귀)에서 적합
    - 이상치 줄이는데 유용
- **주의점**
    - 데이터에 이상치 있을 경우 최대값, 최소값이 크게 왜곡 될 수 있음
        
        ⇒ 데이터 스케일 전 이상치에 대한 처리 선행 필요
        

## ▫︎  비교

| 특성 | 표준화(Standardization) | 정규화(Normalization) |
| --- | --- | --- |
| 적용 후 범위 | 평균 0, 표준편차 1 | 0 에서 1 사이 |
| 사용 시기 | 정규 분포에 가까운 데이터 | 값의 범위가 클 때 |
| 알고리즘 적용 | 거리 기반 알고리즘(KNN, SVM 등) | 신경망, 회귀 등 |
| 이상치에 대한 민감도 | 덜 민감 | 더 민감 |

# ▪︎ 범주형 데이터 처리

### 범주형 데이터

- 수치가 아닌 텍스트 데이터(”사과”, “배”, “포도”)처럼 특정 범주 나타내는 데이터
- 머신러닝 알고리즘은 숫자 데이터 처리하기 때문에 범주형 데이터를 숫자로 변환해야 함

## ▫︎  레이블 인코딩

- 범주형 데이터 정수로 매핑해 각 범주를 고유한 숫자료 변환
    
    ex) 사과 -> 0, 배 -> 1, 포도 -> 2 로 레이블 인코딩
    
- 범주의 순서가 없는데 숫자가 순서를 암시할 수 있음

## ▫︎  원-핫 인코딩

- 범주형 데이터를 이진 벡터로 전환
- 각 범주마다 별도의 열(column)을 만들고 해당 범주에만 1을 표시하고 나머지는 0으로 표시
    
    ex) 사과 → [1,0,0], 배 → [0,1,0], 포도 → [0,0,1]
    
- 범주가 순서 없는 데이터인 경우 적합

## ▫︎  비교

| 특성 | 레이블 인코딩 | 원-핫 인코딩 |
| --- | --- | --- |
| 출력 형식 | 정수 (0,1,2, …) | 이진 벡터 ([1,0,0], …) |
| 순서 정보 암시 | 있음 | 없음 |
| 고차원 문제 | 없음 | 범주가 많으면 열이 많이 생성됨 |
| 사용 적합성 | 순서형 데이터 | 비순서형 데이터 |